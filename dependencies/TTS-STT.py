import sounddevice as sd
import queue
import json
from vosk import Model, KaldiRecognizer
import datetime
import os
import numpy as np
from gtts import gTTS
import tempfile
import subprocess
from typing import Dict, Any
import platform
from pydub import AudioSegment
from pydub.playback import play
import tempfile
import os


from io import BytesIO
from pydub import AudioSegment
from pydub.playback import play

# Configuration
CONFIG = {
    "audio": {
        "samplerate": 16000,
        "device": None,  # Default input device
        "channels": 1,
        "dtype": "int16",
        "blocksize": 8000
    },
    "model_path": "model-hi",  # Hindi model
    "output_file": "hindi_conversation_log.txt"
}

class HindiVoiceAssistant:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.q = queue.Queue()
        self.setup_audio_model()
        self.response_modes = {
            "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø": self.normal_response,
            "‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶": self.translate_response,
            "‡§Æ‡§®‡•ã‡§¶‡§∂‡§æ": self.sentiment_response,
            "‡§∏‡§π‡§æ‡§Ø‡§§‡§æ": self.help_response
        }
        self.current_mode = "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø"
        
        # Hindi question-answer pairs
        self.qa_pairs = {
            "‡§®‡§Æ‡§∏‡•ç‡§§‡•á": "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?",
            "‡§§‡•Å‡§Æ ‡§ï‡•å‡§® ‡§π‡•ã": "‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§µ‡•â‡§á‡§∏ ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§π‡•Ç‡§Å, Python ‡§Æ‡•á‡§Ç ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ",
            "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶": "‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à! ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡•ã‡§à ‡§î‡§∞ ‡§Æ‡§¶‡§¶ ‡§ö‡§æ‡§π‡§ø‡§è?",
            "‡§∏‡§Æ‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•Å‡§Ü ‡§π‡•à": self.get_current_time,
            "‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã": "‡§Æ‡•à‡§Ç ‡§†‡•Ä‡§ï ‡§π‡•Ç‡§Å, ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?",
            "‡§Æ‡•ã‡§° ‡§¨‡§¶‡§≤‡•ã": self.list_modes,
            "‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã": self.shutdown
        }

    def setup_audio_model(self):
        """Initialize Hindi speech recognition model"""
        if not os.path.exists(self.config["model_path"]):
            raise FileNotFoundError(f"Hindi model directory '{self.config['model_path']}' not found")

        self.model = Model(self.config["model_path"])
        self.recognizer = KaldiRecognizer(self.model, self.config["audio"]["samplerate"])
        self.recognizer.SetWords(True)

    

    

    # def text_to_speech(self, text: str):
    #     """Convert text to speech using pydub with proper temp file handling"""
    #     try:
    #         # Create temp file with delete=False and proper permissions
    #         with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
    #             temp_path = f.name
            
    #         # Generate and save audio
    #         tts = gTTS(text=text, lang='hi')
    #         tts.save(temp_path)
            
    #         # Load and play audio
    #         sound = AudioSegment.from_mp3(temp_path)
    #         play(sound)
            
    #     except Exception as e:
    #         print(f"TTS Error: {e}")
    #     finally:
    #         # Ensure cleanup even if errors occur
    #         if os.path.exists(temp_path):
    #             try:
    #                 os.unlink(temp_path)
    #             except PermissionError:
    #                 # File might still be in use, retry after delay
    #                 import time
    #                 time.sleep(0.1)
    #                 os.unlink(temp_path)
    
    def text_to_speech(self, text: str):
        """Convert text to speech without temp files"""
        try:
            # Create in-memory file
            mp3_fp = BytesIO()
            
            # Generate audio directly to memory
            tts = gTTS(text=text, lang='hi')
            tts.write_to_fp(mp3_fp)
            mp3_fp.seek(0)  # Rewind to beginning
            
            # Load and play from memory
            sound = AudioSegment.from_mp3(mp3_fp)
            play(sound)
            
        except Exception as e:
            print(f"TTS Error: {e}")
    

    def audio_callback(self, indata, frames, time, status):
        """Handle audio input"""
        if status:
            print("‚ö†Ô∏è", status, flush=True)
        self.q.put(indata.copy())

    def process_audio(self):
        """Process audio stream and return recognized Hindi text"""
        data = self.q.get()
        if self.recognizer.AcceptWaveform(data.tobytes()):
            result = json.loads(self.recognizer.Result())
            return result.get("text", "").strip()
        return None

    def get_current_time(self, text: str = "") -> str:
        """Get current time in Hindi"""
        now = datetime.datetime.now()
        return f"‡§Ö‡§≠‡•Ä ‡§∏‡§Æ‡§Ø ‡§π‡•à {now.strftime('%H:%M')}"

    def list_modes(self, text: str = "") -> str:
        """List available modes"""
        modes = ", ".join(self.response_modes.keys())
        return f"‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§Æ‡•ã‡§°: {modes}. ‡§Æ‡•ã‡§° ‡§¨‡§¶‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§π‡•á‡§Ç '‡§Æ‡•ã‡§° ‡§¨‡§¶‡§≤‡•ã [‡§Æ‡•ã‡§° ‡§®‡§æ‡§Æ]'"

    def shutdown(self, text: str = "") -> str:
        """Shutdown the assistant"""
        self.text_to_speech("‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§¨‡§Ç‡§¶ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!")
        exit()

    def generate_response(self, text: str) -> str:
        """Generate appropriate Hindi response"""
        text = text.lower()
        
        # Check for direct commands first
        for cmd, response in self.qa_pairs.items():
            if cmd.lower() in text:
                if callable(response):
                    return response(text)
                return response

        # Mode switching
        if "‡§Æ‡•ã‡§° ‡§¨‡§¶‡§≤‡•ã" in text:
            return self.handle_mode_change(text)
        
        # Get response based on current mode
        response_func = self.response_modes.get(self.current_mode, self.normal_response)
        return response_func(text)

    def handle_mode_change(self, text: str) -> str:
        """Change response mode"""
        for mode in self.response_modes:
            if mode in text:
                self.current_mode = mode
                return f"‡§Æ‡•ã‡§° ‡§¨‡§¶‡§≤‡§æ ‡§ó‡§Ø‡§æ: {mode}"
        return "‡§ï‡•É‡§™‡§Ø‡§æ ‡§µ‡•à‡§ß ‡§Æ‡•ã‡§° ‡§®‡§ø‡§∞‡•ç‡§¶‡§ø‡§∑‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç"

    def normal_response(self, text: str) -> str:
        """Default response mode"""
        return "‡§Æ‡•à‡§Ç‡§®‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§∏‡•Å‡§®‡•Ä‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§î‡§∞ ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§∏‡•á ‡§¨‡§§‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?"

    def translate_response(self, text: str) -> str:
        """Translation mode response"""
        return f"(‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§Æ‡•ã‡§°) ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§Æ‡•á‡§Ç: '{text}'"

    def sentiment_response(self, text: str) -> str:
        """Sentiment analysis mode"""
        positive_words = ["‡§Ö‡§ö‡•ç‡§õ‡§æ", "‡§∂‡•Å‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ", "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶", "‡§¨‡§¢‡§º‡§ø‡§Ø‡§æ"]
        if any(word in text for word in positive_words):
            return "‡§Ü‡§™ ‡§∏‡§ï‡§æ‡§∞‡§æ‡§§‡•ç‡§Æ‡§ï ‡§≤‡§ó‡§§‡•á ‡§π‡•à‡§Ç!"
        return "‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§≠‡§æ‡§µ‡§®‡§æ ‡§∏‡§Æ‡§ù‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å..."

    def help_response(self, text: str) -> str:
        """Help mode response"""
        return "‡§Æ‡•à‡§Ç ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å: ‡§∏‡§Æ‡§Ø ‡§¨‡§§‡§æ‡§®‡§æ, ‡§Æ‡•ã‡§° ‡§¨‡§¶‡§≤‡§®‡§æ, ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§"

    def run(self):
        """Main execution loop"""
        self.text_to_speech("‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§µ‡•â‡§á‡§∏ ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§∂‡•Å‡§∞‡•Ç ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à")
        print("üé§ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§µ‡•â‡§á‡§∏ ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø... (‡§∞‡•ã‡§ï‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è '‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã' ‡§ï‡§π‡•á‡§Ç)")
        print(f"‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§Æ‡•ã‡§°: {self.current_mode}\n")

        with sd.InputStream(**self.config["audio"], callback=self.audio_callback):
            with open(self.config["output_file"], "a", encoding="utf-8") as log_file:
                while True:
                    try:
                        text = self.process_audio()
                        if text:
                            print(f"\n‡§Ü‡§™: {text}")
                            response = self.generate_response(text)
                            print(f"‡§∏‡§π‡§æ‡§Ø‡§ï: {response}")
                            self.text_to_speech(response)
                            
                            # Log conversation
                            timestamp = datetime.datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
                            log_file.write(f"{timestamp} User: {text}\n")
                            log_file.write(f"{timestamp} Assistant: {response}\n")
                            log_file.flush()

                    except KeyboardInterrupt:
                        self.shutdown()
                    except Exception as e:
                        print(f"‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}")
                        continue

if __name__ == "__main__":
    try:
        # Verify Hindi model exists
        if not os.path.exists("model-hi"):
            print("‡§ï‡•É‡§™‡§Ø‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç:")
            print("https://alphacephei.com/vosk/models")
            print("‡§î‡§∞ 'model-hi' ‡§®‡§æ‡§Æ ‡§ï‡•á ‡§´‡•ã‡§≤‡•ç‡§°‡§∞ ‡§Æ‡•á‡§Ç ‡§è‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡•à‡§ï‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç")
        else:
            assistant = HindiVoiceAssistant(CONFIG)
            assistant.run()
    except Exception as e:
        print(f"‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠‡§ø‡§ï ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}")