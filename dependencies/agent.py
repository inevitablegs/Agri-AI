import sounddevice as sd
import queue
import json
from vosk import Model, KaldiRecognizer
import datetime
import os
import numpy as np
from typing import Dict, Any
import random

# Configuration
CONFIG = {
    "audio": {
        "samplerate": 44100,
        "device": 2,  # Your microphone array
        "channels": 1,
        "dtype": "int16",
        "blocksize": 8000
    },
    "model_path": "model-hi",
    "output_file": "conversation_log.txt"
}

class VoiceAssistant:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.q = queue.Queue()
        self.setup_audio_model()
        self.response_modes = {
            "echo": self.echo_response,
            "qa": self.qa_response,
            "translate": self.translate_response,
            "sentiment": self.sentiment_response
        }
        self.current_mode = "qa"
        self.qa_pairs = {
            "‡§®‡§Æ‡§∏‡•ç‡§§‡•á": "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§ï‡•à‡§∏‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?",
            "‡§§‡•Å‡§Æ ‡§ï‡•å‡§® ‡§π‡•ã": "‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§Ü‡§µ‡§æ‡§ú ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•Ç‡§Å ‡§ú‡§ø‡§∏‡•á Python ‡§Æ‡•á‡§Ç ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§",
            "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶": "‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à! ‡§ï‡•ã‡§à ‡§î‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ?",
            "‡§∏‡§Æ‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•Å‡§Ü ‡§π‡•à": f"‡§Ö‡§≠‡•Ä ‡§∏‡§Æ‡§Ø ‡§π‡•à {datetime.datetime.now().strftime('%H:%M')}"
        }

    def setup_audio_model(self):
        """Initialize speech recognition model"""
        if not os.path.exists(self.config["model_path"]):
            raise FileNotFoundError(f"Model directory '{self.config['model_path']}' not found")

        self.model = Model(self.config["model_path"])
        self.recognizer = KaldiRecognizer(self.model, self.config["audio"]["samplerate"])
        self.recognizer.SetWords(True)

    def audio_callback(self, indata, frames, time, status):
        """Handle audio input"""
        if status:
            print("‚ö†Ô∏è", status, flush=True)
        self.q.put(indata.copy())

    def process_audio(self):
        """Process audio stream and return recognized text"""
        data = self.q.get()
        if self.recognizer.AcceptWaveform(data.tobytes()):
            result = json.loads(self.recognizer.Result())
            return result.get("text", "").strip()
        return None

    def generate_response(self, text: str) -> str:
        """Generate appropriate response based on mode and input"""
        text = text.lower()
        
        # Mode switching commands
        if "‡§Æ‡•ã‡§° ‡§¨‡§¶‡§≤‡•ã" in text:
            return self.handle_mode_change(text)
        
        # Get response based on current mode
        response_func = self.response_modes.get(self.current_mode, self.qa_response)
        return response_func(text)

    def handle_mode_change(self, text: str) -> str:
        """Change response mode"""
        for mode in self.response_modes:
            if mode in text:
                self.current_mode = mode
                return f"‡§Æ‡•ã‡§° ‡§¨‡§¶‡§≤‡§æ ‡§ó‡§Ø‡§æ: {mode}"
        return "‡§ï‡•É‡§™‡§Ø‡§æ ‡§µ‡•à‡§ß ‡§Æ‡•ã‡§° ‡§®‡§ø‡§∞‡•ç‡§¶‡§ø‡§∑‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç (echo, qa, translate, sentiment)"

    def echo_response(self, text: str) -> str:
        """Simply repeat the input"""
        return f"‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ: {text}"

    def qa_response(self, text: str) -> str:
        """Answer questions from predefined pairs"""
        for question, answer in self.qa_pairs.items():
            if question.lower() in text:
                return answer
        return "‡§Æ‡•à‡§Ç ‡§á‡§∏ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ú‡§æ‡§®‡§§‡§æ‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§á‡§∏‡•á ‡§Ö‡§≤‡§ó ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?"

    def translate_response(self, text: str) -> str:
        """Simulate translation (would connect to real API in production)"""
        return f"(‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§Æ‡•ã‡§°) ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§Æ‡•á‡§Ç ‡§Ø‡§π ‡§π‡•ã‡§ó‡§æ: '{text}'"

    def sentiment_response(self, text: str) -> str:
        """Analyze sentiment (simplified version)"""
        positive_words = ["‡§Ö‡§ö‡•ç‡§õ‡§æ", "‡§∂‡•Å‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ", "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶", "‡§¨‡§¢‡§º‡§ø‡§Ø‡§æ"]
        if any(word in text for word in positive_words):
            return "‡§Ü‡§™ ‡§∏‡§ï‡§æ‡§∞‡§æ‡§§‡•ç‡§Æ‡§ï ‡§≤‡§ó‡§§‡•á ‡§π‡•à‡§Ç!"
        return "‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§≠‡§æ‡§µ‡§®‡§æ ‡§∏‡§Æ‡§ù‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å..."

    def run(self):
        """Main execution loop"""
        print("üé§ ‡§Ü‡§µ‡§æ‡§ú ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø... (‡§∞‡•ã‡§ï‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è Ctrl+C ‡§¶‡§¨‡§æ‡§è‡§Å)")
        print(f"‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§Æ‡•ã‡§°: {self.current_mode}\n")

        with sd.InputStream(**self.config["audio"], callback=self.audio_callback):
            with open(self.config["output_file"], "a", encoding="utf-8") as log_file:
                while True:
                    try:
                        text = self.process_audio()
                        if text:
                            print(f"\n‡§Ü‡§™: {text}")
                            response = self.generate_response(text)
                            print(f"‡§∏‡§π‡§æ‡§Ø‡§ï: {response}")
                            
                            # Log conversation
                            timestamp = datetime.datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
                            log_file.write(f"{timestamp} User: {text}\n")
                            log_file.write(f"{timestamp} Assistant: {response}\n")
                            log_file.flush()

                    except KeyboardInterrupt:
                        print("\nüõë ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§¨‡§Ç‡§¶ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...")
                        break
                    except Exception as e:
                        print(f"‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}")
                        continue

if __name__ == "__main__":
    try:
        assistant = VoiceAssistant(CONFIG)
        assistant.run()
    except Exception as e:
        print(f"‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠‡§ø‡§ï ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}")